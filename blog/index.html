---
layout: page
title: Blog
comments: false
tags: [blog, Evgeniia-Razumovskaia, research, NLP, dialogue systems, welcome, phd-life, phd]
---

<!-- Style for the blog page is borrowed from lena voita's page -->

<style>

  #thumbnail {
    box-shadow: 0 5px 10px rgba(0,0,0,0.19), 0 3px 3px rgba(0,0,0,0.23);
  }
  #thumbnail:hover {
    box-shadow: 0 12px 24px rgba(0,0,0,0.19), 0 8px 8px rgba(0,0,0,0.23);
  }

  .fullCard {
    width: 750px;
    border: 1px solid #ccc;
    border-radius: 5px;
    margin: 10px 5px;
    padding: 4px;

  }
  .cardContent {
    padding: 10px;
    margin: 10px 5px;

  }

  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  paper_link {
  color: #2e678c;
}

paper_link:hover {
  text-decoration: underline;
}

</style>


<div class="fullCard" id="thumbnail" >
    <div class="cardContent">

        <span style="font-size:15px; color:gray">A retrospecive of <b>multilingual sentence encoders</b></span>

        <br/>
        <br/>

        <span style="font-size:14px;">
        This is a post with notes on the paper
          <b><a href="https://arxiv.org/pdf/1812.10464.pdf">
              Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
          </a></b>
          by Mikel Artetxe and Holger Schwenk.
        </span>


        <br/>
        <br/>
        <span style="font-size:15px;">
        <ul>
          <li><b>What is the problem?</b> Multilingual sentence encoders work well <b><i>only</i></b> on the languages and tasks they were trained on. </li>
          <li><b>Proposed solution</b> Sentence encoder trained on 93 languages across 30 language families; 
          it  works well across languages, scripts and NLP tasks. </li>
          <li><b>What's next?</b> We have an encoder which works well on languages it has seen during training and those it hasn't as well. </li>
        </ul>
        </span>
        <br/>

        <a class="pull-left" href='posts/laser' onMouseOver="document.readmore3.src='../images/buttons/read_more_on_push.png';" onMouseOut="document.readmore3.src='../images/buttons/read_more.png';">
        <img src="../images/buttons/read_more.png" name="readmore3" width=100px class="pull-left"></a>
        <a class="pull-left" href="https://arxiv.org/pdf/1812.10464.pdf" onMouseOver="document.readpaper3.src='../images/buttons/read_paper_on_push.png';" onMouseOut="document.readpaper3.src='../images/buttons/read_paper.png';">
        <img src="../images/buttons/read_paper.png" name="readpaper3" width=100px class="pull-left"></a>

        <span style="font-size:15px; text-align: right; float: right; color:gray">March 2021</span>
        <br/>

    </div>
</div>


<!-- ################################################################################### -->


<div class="fullCard" id="thumbnail" >
    <div class="cardContent">

        <span style="font-size:15px; color:gray">A retrospecive of <b>multilingual sentence encoders</b></span>

        <br/>
        <br/>

        <span style="font-size:14px;">
        This is a post with notes on the paper
            <b><a href="https://arxiv.org/pdf/1907.04307.pdf">
                Multilingual Universal Sentence Encoder for Semantic Retrieval
            </a></b>
            by Yinfei Yang, Daniel Cer et al.
        </span>


        <br/>
        <br/>
        <span style="font-size:15px;">
        <ul>
          <li><b>What is the problem?</b> Previously existing models (e.g., BERT) did not produce good cross-lingual sentence representations which could be used across tasks and domains;</li>
          <li><b>Proposed solution</b> Multilingual sentence encoder trained on large corpora in 16 languages which cover multiple tasks such as Question Answering and Natural Language Inference; </li>
          <li><b>What's next?</b> It is tested on transfer to unseen sentence retrieval tasks (with success!!) but not on unseen languages. </li>
        </ul>
        </span>
        <br/>

        <a class="pull-left" href='posts/muse' onMouseOver="document.readmore2.src='../images/buttons/read_more_on_push.png';" onMouseOut="document.readmore2.src='../images/buttons/read_more.png';">
        <img src="../images/buttons/read_more.png" name="readmore2" width=100px class="pull-left"></a>
        <a class="pull-left" href="https://arxiv.org/pdf/1907.04307.pdf" onMouseOver="document.readpaper2.src='../images/buttons/read_paper_on_push.png';" onMouseOut="document.readpaper2.src='../images/buttons/read_paper.png';">
        <img src="../images/buttons/read_paper.png" name="readpaper2" width=100px class="pull-left"></a>

        <span style="font-size:15px; text-align: right; float: right; color:gray">March 2021</span>
        <br/>

    </div>
</div>


<!-- ################################################################################### -->


<div class="fullCard" id="thumbnail" >
    <div class="cardContent">

        <h1 style="font-size:28px;">Welcome! ☀️</h1>

<!--         <span style="font-size:14px;">
        This is a post for the paper
            <a href="https://arxiv.org/pdf/2010.10907.pdf">
                Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation.
            </a>
        </span> -->


<!--         <br/>
        <br/> -->
        <span style="font-size:15px;">
            What will this blog be about? 
            Mostly Natural Language processing and Machine Learning research I find interesting, but not only :)
        </span>

        <br/>
        <a class="pull-left" href='posts/welcome_post' onMouseOver="document.readmore1.src='../images/buttons/read_more_on_push.png';" onMouseOut="document.readmore1.src='../images/buttons/read_more.png';">
        <img src="../images/buttons/read_more.png" name="readmore1" width=100px class="pull-left"></a>

        <span style="font-size:15px; text-align: right; float: right; color:gray">March 2021</span>

        <br/>

    </div>
</div>


<!-- ################################################################################### -->
